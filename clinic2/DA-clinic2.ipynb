{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Placeholder for your group #)\n",
    "\n",
    "(Placeholder for your names)\n",
    "\n",
    "(Placeholder for your i-numbers)\n",
    "\n",
    "**Use of genAI tools (e.g. chatGPT), websites (e.g. stackoverflow)**: *list websites where you found code (or other info) as well as include information on how you used genAI tools*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "# Clinic 2: I heard you are ðŸ‘€ for a ðŸ  in Utrecht \n",
    "\n",
    "By completing and delivering the clinic tasks you will know how to:\n",
    "\n",
    "- Work with real-world, messy datasets that require cleaning and preprocessing  \n",
    "- Perform exploratory data analysis (EDA) to guide modeling decisions  \n",
    "- Engineer new features, including spatial and polynomial features  \n",
    "- Build reusable data processing pipelines in pandas  \n",
    "- Train and evaluate linear and regularized models using scikit-learn  \n",
    "- Use cross-validation to select model hyperparameters  \n",
    "- Interpret models using feature importance techniques  \n",
    "- Assess fairness by analyzing prediction errors across groups and locations  \n",
    "- Communicate technical results clearly to both technical and non-technical audiences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Dates.**\n",
    "\n",
    "- Clinic 2 release: Fri 06 Feb 2026\n",
    "- Clinic 2 due: Mon 23 Feb 2026 late night, wildcards available\n",
    "\n",
    "**Instructions for the deliverable: notebook and video**\n",
    "\n",
    "1. Executed Notebook (.ipynb) (80 points)\n",
    "\n",
    "Your notebook should include the parts as here. All cells must be executed and outputs visible. Include answers to all questions and also explain your reasoning and describe any insights.\n",
    "\n",
    "---\n",
    "2. Short Video Presentation (up to 3 minutes) (20 points)\n",
    "\n",
    "Create a short video aimed at a **general (non-technical) audience** in which you explain:\n",
    "\n",
    "- What problem you were trying to solve\n",
    "- How you built your model (high level)\n",
    "- What features mattered most\n",
    "- Whether the model was fair across neighborhoods\n",
    "- One key insight or takeaway\n",
    "\n",
    "You do **not** need to include code in the video but you **should** include figures and plots. Focus on clarity, intuition and real-world implications.\n",
    "\n",
    "---\n",
    "ðŸŽ¯ Video Guidelines\n",
    "\n",
    "- Maximum length: **3 minutes**\n",
    "- Target audience: non-technical (e.g., city officials, homeowners, journalists)\n",
    "- You may use slides, screen recording or simple visuals\n",
    "- Avoid technical jargon as much as possible\n",
    "- Do **not** use AI-generated voices or AI video generators.  \n",
    "- The presentation must use **your own voice**.\n",
    "\n",
    "---\n",
    "âš–ï¸ Grading Considerations for the Video\n",
    "\n",
    "The video will be evaluated on:\n",
    "\n",
    "- Clarity of explanation\n",
    "- Correctness of interpretation\n",
    "- Engagement with fairness issues\n",
    "- Ability to communicate technical results simply\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“… Submission Format\n",
    "\n",
    "- Upload the executed notebook as `.ipynb`\n",
    "- Upload or link to your video (e.g., unlisted YouTube link, link to some storage space (e.g. google folder), other...)\n",
    "\n",
    "- **Honor code** applies to these tasks.  \n",
    "  If you are not certain about an action, consult with Jerry.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A philosophical note from Jerry on using Language Models (LMs)**\n",
    "\n",
    "You might have thought about it. Are LLMs going to replace data scientists?\n",
    "\n",
    "*Short answer*: No-one knows for sure. But, I have some hope.\n",
    "\n",
    "\n",
    "Here are my thoughts, for this clinic but in general as well. In many of our data analysis tasks we have 3 steps.\n",
    "\n",
    "+ Step 1: Gather context and ask insightful questions. LLMs cannot deeply understand the nuanced desires, abilities, and personalities of complex organizations. At least for now ðŸ™‚\n",
    "\n",
    "+ Step 2: Plan analyses that address your question(s). LLMs can provide advice as you weigh options. But, the choice of \"best\" analysis is often subjective. Experience matters. That's what people will pay you for in the future, not your ability to run Python.\n",
    "\n",
    "+ Step 3: Run the analysis. With proper context and instructions, LLMs can help a lot here! But, you must be able to verify outputs. Don't do analysis by \"vibes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "In this clinic, we will go through the iterative process of specifying, fitting, and refining a linear regression model using real-world housing data from Utrecht. Dataset is inspired from this [paper](https://ictinstitute.nl/utrecht-housing-dataset-2025/), which you are welcome to read!\n",
    "\n",
    "In the first part of the assignment, we will guide you through exploratory data analysis (EDA), laying out the thought process that leads to key data cleaning, transformation, and modeling decisions. We will then specify and fit increasingly refined linear models, providing examples of the type of code and workflow expected in the open-response section.\n",
    "\n",
    "The second part of the assignment is purposefully left open-ended. You will be allowed to build a linear model of your choice (e.g., linear regression, Ridge, Lasso) to better predict housing values.\n",
    "\n",
    "After completing this clinic, you should feel comfortable with:\n",
    "\n",
    "1. Working with a real-world dataset that requires cleaning and preprocessing\n",
    "\n",
    "1. Performing exploratory data analysis to inform modeling decisions\n",
    "\n",
    "1. Building linear and regularized models using `sklearn`\n",
    "\n",
    "1. Creating feature engineering pipelines with `pandas`\n",
    "\n",
    "1. Using cross-validation for model selection and evaluation\n",
    "\n",
    "1. Interpreting residuals and error metrics\n",
    "\n",
    "1. Reflecting on fairness implications in predictive models\n",
    "\n",
    "## Score breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "[Question 1](#q1) | 5\n",
    "[Question 2a](#q2a) | 2\n",
    "[Question 2b](#q2b) | 2\n",
    "[Question 3](#q3) | 2\n",
    "[Question 4](#q4) | 8\n",
    "[Question 5](#q5) | 35\n",
    "[Question 6](#q6) | 15\n",
    "[Question 7](#q7) | 15\n",
    "Total | 80\n",
    "\n",
    "This score will be added to the video score (20), scaled down to 1 and that will be your final clinic score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports (edit as you see fit)\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "#to show big values in numbers and not in scientific format\n",
    "import matplotlib.ticker as mtick\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rcParams['axes.formatter.use_locale'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 The Data\n",
    "\n",
    "The dataset consists of several hundred residential properties in Utrecht and includes structural, spatial, and energy-related features.\n",
    "\n",
    "Some of the key variables include, for more details refer to the `codebook.txt`:\n",
    "\n",
    "```\n",
    "retailvalue â€“ estimated market value of the property (our main prediction target)\n",
    "\n",
    "taxvalue â€“ assessed value used for taxation purposes\n",
    "\n",
    "house-area, lot-area, garden-size â€“ size-related features\n",
    "\n",
    "bathrooms, buildyear â€“ structural characteristics\n",
    "\n",
    "energy-eff â€“ energy efficiency indicator\n",
    "\n",
    "monument â€“ whether the property is a protected historical building\n",
    "\n",
    "zipcode, x-coor, y-coor â€“ location information\n",
    "```\n",
    "\n",
    "Together, these variables describe both the physical properties of homes and aspects related to sustainability and urban geography.\n",
    "\n",
    "Dataset is not split to training/test but we will use one common seed (to rule all splits).\n",
    "\n",
    "### 0.1.1 Housing Valuation and Fairness\n",
    "\n",
    "ðŸŒ In many countries, including the Netherlands, property values are used to determine: property taxes, mortgage conditions, insurance costs.\n",
    "\n",
    "ðŸ’° These values are often estimated using statistical or machine learning models that take into account characteristics such as size, location, and building quality.\n",
    "\n",
    "ðŸŽ¯ While predictive accuracy is important, valuation models can also have distributional consequences. Systematic overvaluation or undervaluation of homes in certain areas or categories (e.g., energy-efficient homes, historic buildings, or specific neighborhoods) can lead to: higher tax burdens for some residents, unfair advantages for others.\n",
    "\n",
    "ðŸ§ª In this clinic, we will not only aim to build accurate predictive models, but also examine who benefits and who may be harmed by modeling errors.\n",
    "\n",
    "ðŸ ðŸ“Š By analyzing residuals and group-wise error patterns (e.g., by zipcode, energy efficiency or monument status), we will reflect on how fairness can be understood in the context of housing valuation. That will also serve as a good basis for the guest lecture we are going to have on March 9th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¥ Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"utrechthousing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ‚ï¸ Create train/test split\n",
    "\n",
    "Since the dataset is not pre-divided into training and test sets, we create our own split. The training set will be used to fit and tune our models, while the test set will be held out to evaluate performance on unseen data. To ensure reproducibility across different runs of the notebook, we fix the random seed before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility (so everyone gets the same split) ###DO NOT CHANGE\n",
    "np.random.seed(1983)\n",
    "\n",
    "# Split: 80% train, 20% test\n",
    "training_data, testing_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2, \n",
    "    random_state=1983\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "528d80c0381c45f44c1734ba04056d63",
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sizes\n",
    "#1516,16\n",
    "print(\"Train shape:\", training_data.shape)\n",
    "#379,16\n",
    "print(\"Test shape:\", testing_data.shape)\n",
    "\n",
    "# They should sum to full dataset\n",
    "assert training_data.shape[0] + testing_data.shape[0] == data.shape[0]\n",
    "\n",
    "# Same columns in both\n",
    "assert set(training_data.columns) == set(testing_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e7e804b381f5c3ba5ea29b2df70bc92c",
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  The Ames data set contains information that typical homebuyers would want to know.  A more detailed description of each variable is included in `codebook.txt`.  **You should take some time to familiarize yourself with the codebook before moving forward.** If you find any issues or inconsistencies in the codebook, please report them to us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f542e637735a9ff2be37b5e2f2ea35b1",
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Guided Modeling\n",
    "\n",
    "In the first part of the assignment, we will take you step-by-step through one cycle of the modeling process.  Along the way, we will provide commentary to give you a sense of the thought process that goes into building a model. We give examples on most of the common cases we have explored (EDA, missing values, feature engineering etc.), but feel free to extend this analyses for your final model.\n",
    "\n",
    "## 1.1 EDA\n",
    "Naturally, the first thing we want to do is get a feel for our data.  In this section, we will make a series of exploratory visualizations.  The plots we ask you to reproduce here are far from exhaustive. **When you build your own model in the second part of this assignment, you will want to delve deeper into the data.**\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### 1.1.1 Retail-value\n",
    "We begin by examining a [raincloud plot](https://www.kaggle.com/code/carlmcbrideellis/box-strip-violin-raincloud-plot) (yet another name for a combination of a KDE, a boxplot, and a boxplot all-in-one) of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.histplot(\n",
    "    training_data[\"retailvalue\"],\n",
    "    kde=True,\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    training_data[\"retailvalue\"],\n",
    "    orient=\"h\",\n",
    "    jitter=0.4,\n",
    "    size=3,\n",
    "    ax=axs[1],\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    training_data[\"retailvalue\"],\n",
    "    orient=\"h\",\n",
    "    width=0.4,\n",
    "    ax=axs[1],\n",
    "    showfliers=False,\n",
    ")\n",
    "\n",
    "# Align axes\n",
    "spacer = np.max(training_data[\"retailvalue\"]) * 0.05\n",
    "xmin = np.min(training_data[\"retailvalue\"]) - spacer\n",
    "xmax = np.max(training_data[\"retailvalue\"]) + spacer\n",
    "axs[0].set_xlim((xmin, xmax))\n",
    "axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_visible(False)\n",
    "axs[1].yaxis.set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "axs[1].set_facecolor(\"white\")\n",
    "#remove scientific format\n",
    "axs[1].xaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics for price\n",
    "training_data[\"retailvalue\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `retailvalue` in the training set is left-skew.\n",
    "1. The mean of `retailvalue` in the training set is greater than the median.\n",
    "1. 75% of the houses in the training set sold for less than 911,250.00. euro\n",
    "\n",
    "If you have trouble answering the questions above, discuss them in class with each other and confirm with a TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Retail Value vs House Area\n",
    "\n",
    "Next, we examine `retailvalue` vs `house-area` (living area in mÂ²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= sns.jointplot(\n",
    "    x=\"house-area\",\n",
    "    y=\"retailvalue\",\n",
    "    data=training_data,\n",
    "    kind=\"reg\",\n",
    "    ratio=4,\n",
    "    space=0,\n",
    "    scatter_kws={\"s\": 12, \"alpha\": 0.25},\n",
    "    line_kws={\"color\": \"black\"}\n",
    ")\n",
    "\n",
    "g.ax_joint.xaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))\n",
    "g.ax_joint.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often expect a roughly linear relationship between size and value, but we should also look for unusual points (potential outliers). In this dataset, a small number of houses have house-area above 300 mÂ². Letâ€™s inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2house1 and q2house2 should be integers\n",
    "q2house1 = training_data.loc[training_data[\"house-area\"] > 300, \"id\"].iloc[0].item()\n",
    "q2house2 = training_data.loc[training_data[\"house-area\"] > 300, \"id\"].iloc[1].item()\n",
    "\n",
    "q2house1, q2house2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we write a function `remove_outliers` that removes outliers from a data set based off a threshold value of a variable. For example, `remove_outliers(training_data, 'house-area', upper=300)` should return a data frame with only observations that satisfy `house-area` less than or equal to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "    \"\"\"\n",
    "    return data.loc[(data[variable] > lower) & (data[variable] < upper)]\n",
    "\n",
    "\n",
    "training_data = remove_outliers(training_data, \"house-area\", upper=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure the two observations were removed\n",
    "assert training_data.shape[0] == 1514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Zipcode vs Retail Value\n",
    "\n",
    "Next we explore this relationship. We have a small set of 4-digit zipcodes. Location is often one of the strongest predictors of housing value, so letâ€™s inspect how values differ across zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"zipcode\",\n",
    "    y=\"retailvalue\",\n",
    "    data=training_data.sort_values(\"zipcode\"),\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"zipcode\",\n",
    "    data=training_data.sort_values(\"zipcode\"),\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[0].axhline(\n",
    "    y=training_data[\"retailvalue\"].median(),\n",
    "    color=\"green\",\n",
    "    linestyle=\"dotted\"\n",
    ")\n",
    "\n",
    "for patch in axs[1].patches:\n",
    "    x = patch.get_bbox().get_points()[:, 0]\n",
    "    y = patch.get_bbox().get_points()[1, 1]\n",
    "    axs[1].annotate(f\"{int(y)}\", (x.mean(), y), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Are there differences or maybe outliers?\n",
    "\n",
    "While the dataset includes a zipcode variable, these administrative boundaries are relatively coarse and may not fully capture finer-grained spatial patterns in housing prices. Homes that are geographically close to each other can belong to different zipcodes, while homes far apart may share the same zipcode. As a result, relying solely on zipcode may obscure important local effects related to accessibility, amenities, and neighborhood characteristics.\n",
    "\n",
    "To better represent spatial structure in the data, we will create a new variable that groups houses into data-driven neighborhoods based directly on their geographic coordinates (`x-coor` and `y-coor`). Using a simple clustering technique, we partition the city into contiguous spatial regions that reflect natural groupings of properties. These spatial neighborhoods provide a more flexible and fine-grained representation of location than zipcode alone.\n",
    "\n",
    "After constructing these spatial neighborhoods, we will identify the most expensive ones (based on median housing value) and create a binary indicator variable, `in_rich_neighborhood`, which marks whether a house lies in one of these high-value areas. \n",
    "\n",
    "This additional feature allows our models to incorporate local spatial effects more effectively and provides a useful lens for later fairness analysis, where we will examine whether prediction errors systematically differ across regions of the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def add_spatial_neighborhoods(data, k=8, random_state=1983):\n",
    "    data = data.copy()\n",
    "    \n",
    "    coords = data[[\"x-coor\", \"y-coor\"]]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
    "    data[\"spatial_neighborhood\"] = kmeans.fit_predict(coords)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = add_spatial_neighborhoods(training_data, k=8)\n",
    "training_data[\"spatial_neighborhood\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=\"x-coor\",\n",
    "    y=\"y-coor\",\n",
    "    hue=\"spatial_neighborhood\",\n",
    "    data=training_data,\n",
    "    palette=\"tab10\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Data-driven Spatial Neighborhoods\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's replot the previous figure but with this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"spatial_neighborhood\",\n",
    "    y=\"retailvalue\",\n",
    "    data=training_data.sort_values(\"spatial_neighborhood\"),\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.countplot(\n",
    "    x=\"spatial_neighborhood\",\n",
    "    data=training_data.sort_values(\"spatial_neighborhood\"),\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[0].axhline(\n",
    "    y=training_data[\"retailvalue\"].median(),\n",
    "    color=\"green\",\n",
    "    linestyle=\"dotted\"\n",
    ")\n",
    "\n",
    "for patch in axs[1].patches:\n",
    "    x = patch.get_bbox().get_points()[:, 0]\n",
    "    y = patch.get_bbox().get_points()[1, 1]\n",
    "    axs[1].annotate(f\"{int(y)}\", (x.mean(), y), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we managed to have some more variation and seems that in some cases retail values differ by the location and the number of observations is not identical across zipcodes.\n",
    "\n",
    "Let's apply a simple binning trick and mark the top-3 locations by median retail value as â€œpricey neighborhoodsâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pricey_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Returns a list of the top-n neighboorhoods by aggregated retailvalue (default: median).\n",
    "    \"\"\"\n",
    "    tmp = data.groupby(\"spatial_neighborhood\")[\"retailvalue\"].agg(metric).sort_values(ascending=False)\n",
    "    return tmp.head(n).index.tolist()\n",
    "\n",
    "pricey_locs = find_pricey_neighborhoods(training_data, 3, np.median)\n",
    "pricey_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add such a categorization to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_pricey_neighborhood(data, locs):\n",
    "    \"\"\"\n",
    "    Adds a binary column in_pricey_neighborhoods:\n",
    "      1 if location is in the provided list, else 0\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data[\"in_pricey_neighborhoods\"] = data[\"spatial_neighborhood\"].isin(locs).astype(int)\n",
    "    return data\n",
    "\n",
    "training_data = add_in_pricey_neighborhood(training_data, pricey_locs)\n",
    "assert training_data[\"in_pricey_neighborhoods\"].isnull().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (curiosity): Which are these expensive neighboorhoods in Utrecht?\n",
    "\n",
    "Feel free to use (or adapt) this feature in your latter analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Missing Data\n",
    "\n",
    "Let's see if our data set has any missing values. \n",
    "\n",
    "ðŸ‘‰ You should observe that there are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = training_data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "assert isinstance(missing_counts, pd.Series)\n",
    "assert missing_counts.size == training_data.shape[1]\n",
    "assert set(missing_counts.index.values) == set(training_data.columns.values)\n",
    "\n",
    "missing_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Feature Engineering\n",
    "\n",
    "In this section we will create a new feature out of existing ones through a simple data transformation.  When you move on to create your own model, you may want to try out more complex transformations.\n",
    "\n",
    "### 1.3.1 House age\n",
    "\n",
    "Weâ€™ll create a variable `house_age` based on `buildyear`. Since the dataset does not include a valuation year column, weâ€™ll define age relative to a fixed reference year (2025 is fine for this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_house_age(data, reference_year=2025):\n",
    "    data = data.copy()\n",
    "    data[\"house_age\"] = reference_year - data[\"buildyear\"]\n",
    "    return data\n",
    "\n",
    "training_data = add_house_age(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no missing values were created\n",
    "assert ~training_data[\"house_age\"].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Total Outdoor Space\n",
    "\n",
    "Outdoor space can matter a lot for price. We create:\n",
    "\n",
    "```total_outdoor = lot-area + garden-size```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_outdoor(data):\n",
    "    data = data.copy()\n",
    "    data[\"total_outdoor\"] = data[\"lot-area\"] + data[\"garden-size\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple check\n",
    "training_data = add_total_outdoor(training_data)\n",
    "assert ~training_data[\"total_outdoor\"].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 <a id=\"q1\"></a>\n",
    "\n",
    "Propose and justify at least two new features derived from existing variables.\n",
    "Explain why they might improve predictive performance and how they could affect fairness.\n",
    "\n",
    "(at this point we don't care if we are going to use them or not, we just make some hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for feature 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "justification for feature 1 (predictive+fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for feature 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "justification for feature 2 (predictive+fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling\n",
    "\n",
    "Weâ€™ve finally gotten to a point where we can specify a simple model. Since the Utrecht dataset is not pre-split into training and test files, we will create our own split. We will treat `utrechthousing.csv` as the complete dataset, use `train_test_split` to create `training_data` and `testing_data`, and then evaluate model performance on the test set.\n",
    "\n",
    "As before, we will keep our preprocessing in reusable functions so we can apply the exact same pipeline to both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fresh copy of the data\n",
    "full_data = pd.read_csv(\"utrechthousing.csv\")\n",
    "\n",
    "# Reproducible split\n",
    "training_data, testing_data = train_test_split(full_data, test_size=0.2, random_state=1983)\n",
    "\n",
    "# Sanity checks\n",
    "assert training_data.shape == (1516, 16) #note that we are re-loading the dataset here and we apply pre-processing again later\n",
    "assert testing_data.shape == (379, 16)\n",
    "assert set(training_data.columns) == set(testing_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we copy the functions we used before (you can add yours of course or modify them). Actually, we expect that you adapt this part for the next part (Question 5) but feel free to already adapt it here aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    return data.reindex(columns=columns)\n",
    "\n",
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    return data.loc[(data[variable] > lower) & (data[variable] < upper)]\n",
    "\n",
    "def add_house_age(data, reference_year=2025):\n",
    "    data = data.copy()\n",
    "    data[\"house_age\"] = reference_year - data[\"buildyear\"]\n",
    "    return data\n",
    "\n",
    "def add_total_outdoor(data):\n",
    "    data = data.copy()\n",
    "    data[\"total_outdoor\"] = data[\"lot-area\"] + data[\"garden-size\"]\n",
    "    return data\n",
    "\n",
    "def fit_spatial_neighborhood_model(train_data, k=8, random_state=1337):\n",
    "    coords = train_data[[\"x-coor\", \"y-coor\"]]\n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)\n",
    "    kmeans.fit(coords)\n",
    "    return kmeans\n",
    "\n",
    "def add_spatial_neighborhood(data, kmeans):\n",
    "    data = data.copy()\n",
    "    data[\"spatial_neighborhood\"] = kmeans.predict(data[[\"x-coor\", \"y-coor\"]])\n",
    "    return data\n",
    "\n",
    "def find_rich_spatial_neighborhoods(data, n=3, metric=np.median):\n",
    "    # Top-n clusters by median retailvalue\n",
    "    tmp = (\n",
    "        data.groupby(\"spatial_neighborhood\")[\"retailvalue\"]\n",
    "        .agg(metric)\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    return tmp.head(n).index.tolist()\n",
    "\n",
    "def add_in_rich_neighborhood(data, rich_clusters):\n",
    "    data = data.copy()\n",
    "    data[\"in_rich_neighborhood\"] = data[\"spatial_neighborhood\"].isin(rich_clusters).astype(int)\n",
    "    return data\n",
    "\n",
    "def add_location_terms(data):\n",
    "    \"\"\"\n",
    "    Adds simple nonlinear location terms to allow spatial curvature with linear models.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data[\"x2\"] = data[\"x-coor\"] ** 2\n",
    "    data[\"y2\"] = data[\"y-coor\"] ** 2\n",
    "    data[\"xy\"] = data[\"x-coor\"] * data[\"y-coor\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Reusable Pipeline\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, this should be sufficient motivation to abstract parts of our code into reusable functions/methods.  We will now encapsulate our entire pipeline into a single function `process_data_gm`.  gm is shorthand for \"guided model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1 Reusable Pipeline\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    return data.reindex(columns=columns)\n",
    "\n",
    "def process_data_gm1(data):\n",
    "    # -------------------\n",
    "    # Clean Data\n",
    "    # -------------------\n",
    "    data = remove_outliers(data, \"house-area\", upper=300)\n",
    "\n",
    "    # -------------------\n",
    "    # Transform Data\n",
    "    # -------------------\n",
    "    data = add_house_age(data)\n",
    "    data = add_total_outdoor(data)\n",
    "\n",
    "    # -------------------\n",
    "    # Select modeling columns\n",
    "    # -------------------\n",
    "    data = select_columns(\n",
    "        data,\n",
    "        \"retailvalue\",\n",
    "        \"house-area\",\n",
    "        \"bathrooms\",\n",
    "        \"total_outdoor\",\n",
    "        \"house_age\",\n",
    "        \"balcony\",\n",
    "        \"energy-eff\",\n",
    "        \"monument\"\n",
    "    )\n",
    "\n",
    "    # -------------------\n",
    "    # Split predictors/target\n",
    "    # -------------------\n",
    "    X = data.drop([\"retailvalue\"], axis=1)\n",
    "    y = data[\"retailvalue\"]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way of writing the same code above explicitly allows us to think about our data flowing through a [pipeline](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html) where the output of one function is the input of the next.  Carefully thought out function names make the code self-documenting: you can just read off the intended high-level processing steps from top to bottom.\n",
    "\n",
    "You are not required to use this style of coding.  We just wanted to point out that it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_gm1(data):\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        # -------------------\n",
    "        # Clean Data\n",
    "        # -------------------\n",
    "        .pipe(remove_outliers, \"house-area\", upper=300)\n",
    "\n",
    "        # -------------------\n",
    "        # Transform Data\n",
    "        # -------------------\n",
    "        .pipe(add_house_age)\n",
    "        .pipe(add_total_outdoor)\n",
    "\n",
    "        # -------------------\n",
    "        # Select columns\n",
    "        # -------------------\n",
    "        .pipe(select_columns,\n",
    "              \"retailvalue\",\n",
    "              \"house-area\",\n",
    "              \"bathrooms\",\n",
    "              \"total_outdoor\",\n",
    "              \"house_age\",\n",
    "              \"balcony\",\n",
    "              \"energy-eff\",\n",
    "              \"monument\")\n",
    "    )\n",
    "\n",
    "    X = data.drop([\"retailvalue\"], axis=1)\n",
    "    y = data[\"retailvalue\"]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Fitting our first model\n",
    "\n",
    "We are finally going to fit a model (yay!). This part is slightly unceremonious since we did much of the heavy lifting in the previous sections. The model we will fit can be written as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{retailvalue} =\\;& \\theta_0 \n",
    "+ \\theta_1 \\times \\text{HouseArea} \n",
    "+ \\theta_2 \\times \\text{Bathrooms} \\\\\n",
    "&+ \\theta_3 \\times \\text{TotalOutdoor}\n",
    "+ \\theta_4 \\times \\text{HouseAge} \\\\\n",
    "&+ \\theta_5 \\times \\text{EnergyEfficiency}\n",
    "+ \\theta_6 \\times \\text{Monument}\n",
    "+ \\theta_7 \\times \\text{Balcony}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- `HouseArea` corresponds to `house-area`  \n",
    "- `Bathrooms` corresponds to `bathrooms`  \n",
    "- `TotalOutdoor = lot-area + garden-size`  \n",
    "- `HouseAge = current year âˆ’ buildyear`  \n",
    "- `EnergyEfficiency` corresponds to `energy-eff`  \n",
    "- `Monument` is an indicator for historic buildings  \n",
    "- `Balcony` is an indicator for balcony presence  \n",
    "\n",
    "\n",
    "#### Question 2a <a name=\"q1a\"></a>\n",
    "Remove the commenting and fill in the ellipses `...` below with `X_train`, `y_train`, `X_test`, or `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process our training and test data in exactly the same way\n",
    "# Our functions make this very easy!\n",
    "..., ... = process_data_gm1(train)\n",
    "..., ... = process_data_gm1(test)\n",
    "guidedmodel1 = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Fill in the ... below with X_train, y_train, X_train, or X_test.\n",
    "# Remember to uncomment\n",
    "guidedmodel1.fit(..., ...)\n",
    "y_fitted = guidedmodel1.predict(...)\n",
    "y_predicted = guidedmodel1.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the result\n",
    "\n",
    "#print(y_fitted.mean())\n",
    "#print(y_predicted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you fail these, might still be okay (but good to check your model, split etc.)\n",
    "assert 790000 <= y_fitted.mean() <= 8000000\n",
    "assert 780000 <= y_predicted.mean() <= 790000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean prediction should not be wildly off from mean actual target in training/test\n",
    "assert abs(y_fitted.mean() - y_train.mean()) / y_train.mean() < 0.25\n",
    "assert abs(y_predicted.mean() - y_test.mean()) / y_test.mean() < 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use Root-Mean-Square Error (RMSE) to measure the quality of our models.  As a reminder, this quantity is defined as:\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price of house} - \\text{predicted price of house})^2}{\\text{# of houses in test set}}}$$\n",
    "\n",
    "#### Question 2b <a name=\"q1b\"></a>\n",
    "\n",
    "Write a function `rmse` that calculates the RMSE of a model.  Again, make sure you are taking advantage of vectorized code.  This can be solved without any iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      actual (1D array-like): vector of actual values\n",
    "      predicted (1D array-like): vector of predicted/fitted values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    \n",
    "    #your code goes here \n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the error\n",
    "\n",
    "#rmse_value = rmse(y_test, y_predicted)\n",
    "#rmse_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE should be smaller than the spread (std) of the target, otherwise the model is doing very poorly\n",
    "assert rmse_value < y_test.std()\n",
    "assert 35000 <= rmse(y_test, y_predicted) <= 37000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Checking our model: Residual Plots\n",
    "\n",
    "Recall from the lectures that one way of diagnosing a model is through a residual plot. Here we plot the actual housing values (`retailvalue`) against the residuals of the model. Ideally, we would see a horizontal line of points at 0 (perfect prediction!). The next best outcome would be a roughly homogeneous cloud of points centered around 0.\n",
    "\n",
    "However, since our first model is intentionally simple, we may observe systematic patterns in the residuals. In particular, it is common for linear models to underpredict very expensive homes and overpredict cheaper ones. Such patterns indicate that the model is underfitting and failing to capture more complex relationships in the data. You will likely want to address these issues when building your own final model in the open-response section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm1_residuals = y_test - y_predicted\n",
    "\n",
    "ax = sns.regplot(x=y_test, y=gm1_residuals)\n",
    "ax.set_xlabel(\"Retail Value (Test Data)\")\n",
    "ax.set_ylabel(\"Residuals (Actual Value - Predicted Value)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Regularizing our model\n",
    "\n",
    "Ok, so let's make our modeling a little more fancy by regularizing the coefficients. This second model will use the Lasso, but you are free to use Ridge or other regularized linear models in your own work.\n",
    "\n",
    "Before applying regularization, we need to standardize our predictor variables. This is necessary because regularization penalizes large coefficients, and variables measured on different scales would otherwise be treated unfairly. By standardizing each predictor to have mean 0 and standard deviation 1, we ensure that the penalty is applied consistently across features.\n",
    "\n",
    "#### Question 3 <a name=\"q3\"></a>\n",
    "\n",
    "Write a function that standardizes the columns of a data frame containing only numeric columns.  Be sure to make use of vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(data):\n",
    "    '''\n",
    "    Input:\n",
    "      data (data frame): contains only numeric columns\n",
    "    Output:\n",
    "      data frame, the same data, except each column is standardized \n",
    "      to have 0-mean and unit variance\n",
    "    '''\n",
    "    #your code goes here [1 line should suffice, don't go nuclear]\n",
    "    \n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple test of the standardization function\n",
    "#test_standardize_df = standardize_columns(\n",
    "#    training_data[[\"retailvalue\", \"house-area\"]]\n",
    "#)\n",
    "\n",
    "# Make sure the mean is approximately zero\n",
    "assert -0.001 < test_standardize_df.mean().sum() < 0.001\n",
    "\n",
    "# Make sure the standard deviation is approximately one\n",
    "assert 1.9 < test_standardize_df.std().sum() < 2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a new processing pipeline for our regularized model. This pipeline is similar to the one used for the simple linear regression model, except that we standardize the predictor variables before fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_gm2(data):\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        # -------------------\n",
    "        # Clean Data\n",
    "        # -------------------\n",
    "        .pipe(remove_outliers, \"house-area\", upper=300)\n",
    "\n",
    "        # -------------------\n",
    "        # Feature engineering\n",
    "        # -------------------\n",
    "        .pipe(add_house_age)\n",
    "        .pipe(add_total_outdoor)\n",
    "\n",
    "        # -------------------\n",
    "        # Select modeling columns\n",
    "        # -------------------\n",
    "        .pipe(select_columns,\n",
    "              \"retailvalue\",\n",
    "              \"house-area\",\n",
    "              \"bathrooms\",\n",
    "              \"total_outdoor\",\n",
    "              \"house_age\",\n",
    "              \"balcony\",\n",
    "              \"energy-eff\",\n",
    "              \"monument\")\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: \n",
    "    # Standardize predictors (but not the target)\n",
    "    # what will happen if we don't standardize?\n",
    "    X = standardize_columns(data.drop([\"retailvalue\"], axis=1))\n",
    "    y = data[\"retailvalue\"]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be instructive to see the cross-validation procedure explicitly once.  You should be able to understand what each part of the code is doing below, but we do not expect you to use this code for your own model (use [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "X_train, y_train = process_data_gm2(training_data)\n",
    "X_test, y_test = process_data_gm2(testing_data)\n",
    "\n",
    "# Specify the model\n",
    "guidedmodel2 = lm.Lasso(copy_X=True)\n",
    "\n",
    "# Specify CV method and grid of regularization values\n",
    "five_fold_cv = KFold(n_splits=5)\n",
    "alphas = np.arange(0.001, 10, 0.5)\n",
    "\n",
    "rmses = np.zeros(len(alphas))\n",
    "\n",
    "# Grid search over alphas\n",
    "for i, alpha in enumerate(alphas):\n",
    "    guidedmodel2.set_params(alpha=alpha)\n",
    "    model_rmse = 0\n",
    "\n",
    "    for train_index, test_index in five_fold_cv.split(X_train):\n",
    "        X_fold_train = X_train.iloc[train_index]\n",
    "        y_fold_train = y_train.iloc[train_index]\n",
    "        X_fold_test = X_train.iloc[test_index]\n",
    "        y_fold_test = y_train.iloc[test_index]\n",
    "\n",
    "        guidedmodel2.fit(X_fold_train, y_fold_train)\n",
    "        y_fold_predicted = guidedmodel2.predict(X_fold_test)\n",
    "\n",
    "        model_rmse += rmse(y_fold_test, y_fold_predicted)\n",
    "\n",
    "    rmses[i] = model_rmse / 5\n",
    "\n",
    "optimal_alpha = alphas[rmses == np.min(rmses)][0]\n",
    "\n",
    "guidedmodel2.set_params(alpha=optimal_alpha)\n",
    "guidedmodel2.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = guidedmodel2.predict(X_test)\n",
    "\n",
    "print(f\"The validation RMSE for this model with \"\n",
    "      f\"alpha={optimal_alpha} is {rmse(y_test, y_predicted)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Lasso Path\n",
    "\n",
    "Letâ€™s examine how RMSE varies across different values of the regularization parameter ($\\lambda$ in lecture, `alpha` in `sklearn`). This is known as the regularization path. The dashed red line marks the value of `alpha` that minimizes RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, rmses)\n",
    "plt.axvline(x=optimal_alpha, color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Average LASSO RMSE Path\")\n",
    "ax.set_xlabel(\"Regularization Level (alpha)\")\n",
    "ax.set_ylabel(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative approach: You can also repeat the regularized regression using `LassoCV`, which automatically performs cross-validation over a grid of regularization values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Lasso Residual Plot\n",
    "\n",
    "Looking at the residual plot for our L1 regularized linear model, it's clear the regularization did not solve the problems we saw in the simple model.  It seems you have your work cut out for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm2_residuals = y_test - y_predicted\n",
    "\n",
    "ax = sns.regplot(x=y_test, y=gm2_residuals)\n",
    "ax.set_xlabel(\"Retail Value (Test Data)\")\n",
    "ax.set_ylabel(\"Residuals (Actual Value - Predicted Value)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "The following questions are supposed to hep you understand the impact of regularization.\n",
    "\n",
    "4a) Does adding location features change the chosen `alpha` compared to the non-location model?\n",
    "\n",
    "4b) Does the test RMSE improve?\n",
    "\n",
    "4c) How many coefficients become exactly zero? Which ones?\n",
    "\n",
    "4d) Do you observe any signs of underfitting or overfitting in residual plots after adding location?\n",
    "\n",
    "Note: Regularization thrives in cases where the dataset is messy (or when there are correlations with the features so it's fine if you don't observe strong effects as we saw in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Let's improve the model, bring out the big guns...\n",
    "\n",
    "In this part of the clinic, you are asked to go beyond the guided example and design your own predictive model.\n",
    "\n",
    "You may use any **linear model** discussed in class (perhaps with non-linear polynomial features). Your goal is to **improve prediction performance** on unseen data, measured using **Root Mean Squared Error (RMSE)**.\n",
    "\n",
    "---\n",
    "### ðŸ“‹ What you should do\n",
    "\n",
    "1. Construct new features based on existing variables:\n",
    "   - Spatial features (latitude, longitude, neighborhoods, clusters)\n",
    "   - Polynomial features (e.g., squared terms, interactions)\n",
    "   - Aggregated or transformed variables (e.g., total outdoor space, house age)\n",
    "2. Select a set of predictors you believe will improve performance.\n",
    "3. Build a reusable data processing pipeline (similar to the guided model).\n",
    "4. Train a linear or regularized linear model using the training data.\n",
    "5. Evaluate your model using RMSE on the test set.\n",
    "\n",
    "You are encouraged to experiment and justify your modeling choices.\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Overfitting Check\n",
    "\n",
    "- Models that perform extremely well on the training set but poorly on unseen data (we keep a set aside).\n",
    "- You should aim for a balance between accuracy and generalization.\n",
    "\n",
    "Using cross-validation and regularization is strongly recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Scheme\n",
    "\n",
    "Your model will be assessed based on:\n",
    "\n",
    "- Predictive performance (RMSE)\n",
    "- Soundness of your modeling pipeline\n",
    "- Feature engineering choices (including polynomial features where appropriate)\n",
    "- Evidence of avoiding overfitting\n",
    "- Clear explanation of your approach\n",
    "\n",
    "There is no single â€œcorrectâ€ model â€” thoughtful experimentation is the goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 <a name=\"q3\"></a>\n",
    "\n",
    "Just as in the guided model above, you should encapsulate as much of your workflow into functions as possible.  Define `process_data_fm` and `final model` in the cell below. In order to calculate your final model's RMSE, we will run the code in the cell after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Solution to Open-Response \n",
    "# =========================\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "#from sklearn import linear_model as lm\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utility functions (e.g. rmse)\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Feature engineering (everything you carry from parts 1 and 2)\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Final processing pipeline (feel free to ingore but is handy to use)\n",
    "# -------------------------\n",
    "def process_data_fm(data):#zipcode_categories, kmeans_model, k_clusters=10):\n",
    "#you might modify this if needed e.g. see below if you use the kmeans exampe or other input\n",
    "#def process_data_fm(data) #zipcode_categories, kmeans_model, k_clusters=10):\n",
    "    \"\"\"\n",
    "    Final model processing:\n",
    "      - Clean: outliers\n",
    "      - Transform: engineered features\n",
    "      - Encode: zipcode + spatial cluster\n",
    "      - Standardize: predictors\n",
    "      - Return: X, y\n",
    "    \"\"\"\n",
    "# code here\n",
    " \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Train/test split (single file)\n",
    "# =========================\n",
    "#reloading the data jst in case, same train/test spit\n",
    "full_data = pd.read_csv(\"utrechthousing.csv\")\n",
    "training_data, testing_data = train_test_split(full_data, test_size=0.2, random_state=1983)\n",
    "\n",
    "# pre-process data\n",
    "#X_train, y_train = process_data_fm(training_data)\n",
    "#X_test, y_test = process_data_fm(testing_data)\n",
    "\n",
    "# ============================\n",
    "# Final model (the big winner)\n",
    "# ============================\n",
    "# final_model = ...\n",
    "\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "#y_pred_train = final_model.predict(X_train)\n",
    "#y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "#training_score = rmse(y_train, y_pred_train)\n",
    "#test_score = rmse(y_test, y_pred_test)\n",
    "\n",
    "#print(\"Chosen alpha:\", final_model.alpha_)\n",
    "#print(\"Chosen l1_ratio:\", final_model.l1_ratio_)\n",
    "#print(\"Training RMSE:\", training_score)\n",
    "#print(\"Test RMSE:\", test_score)\n",
    "\n",
    "# Optional: see which features survived regularization\n",
    "#coef = pd.Series(final_model.coef_, index=X_train.columns).sort_values(key=np.abs, ascending=False)\n",
    "#print(\"\\nTop coefficients by absolute value:\")\n",
    "#print(coef.head(15))\n",
    "\n",
    "#something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = pd.read_csv('ames_train.csv')\n",
    "#X_train, y_train = process_data_fm(training_data)\n",
    "#final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assessing Feature Importance via Perturbation Tests\n",
    "\n",
    "So far, we have evaluated our models using prediction error. However, understanding **which features drive predictions** is equally important â€” especially when models are used in socially sensitive contexts such as housing valuation.\n",
    "\n",
    "One intuitive way to assess feature importance is through a **perturbation (permutation) test**. The idea is simple (and we discussed it in class after regularization - so refer to the slides of Chapter/Lecture VI as well):\n",
    "\n",
    "> If a feature is important, randomly shuffling its values should significantly worsen model performance.\n",
    "\n",
    "This breaks the relationship between the feature and the target while keeping the rest of the data unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Intuition\n",
    "\n",
    "- Small change in RMSE â†’ feature not very important  \n",
    "- Large increase in RMSE â†’ feature highly influential  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‹ Procedure\n",
    "\n",
    "1. Measure the original model RMSE on the test set  \n",
    "2. For each feature:\n",
    "   - Shuffle its values in the test data  \n",
    "   - Recompute RMSE  \n",
    "   - Record the increase in error  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Implement a perturbation test to estimate the importance of each feature in your model.\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "- Which features appear most influential?\n",
    "- Are any features surprisingly unimportant?\n",
    "- (include any other interesting observation you make)\n",
    "\n",
    "Reflect briefly on what this means for both prediction performance and fairness. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation_importance(model, X_test, y_test, metric=rmse):\n",
    "    \"\"\"\n",
    "    Computes feature importance via perturbation tests.\n",
    "    \n",
    "    Returns a Series indexed by feature name with RMSE increase values.\n",
    "    \"\"\"\n",
    "    \n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Make sure we use the model that was actually fit\n",
    "# (final_model was fit on X_train from process_data_fm)\n",
    "model = final_model\n",
    "\n",
    "# Align feature columns (protects against column order / missing dummies / extra columns)\n",
    "#X_test_aligned = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "feature_importance = perturbation_importance(\n",
    "    model, \n",
    "    X_test, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "feature_importance.plot(kind=\"bar\")\n",
    "plt.ylabel(\"Increase in RMSE after perturbation\")\n",
    "plt.title(\"Feature Importance via Perturbation Test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Analysis and answers to questions goes here**\n",
    "\n",
    "more text goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assessing Fairness Through Error Analysis Across Locations\n",
    "\n",
    "High predictive accuracy does not necessarily imply a fair model. In housing valuation, systematic over- or under-estimation in certain areas may disproportionately affect specific communities.\n",
    "\n",
    "To explore potential fairness issues, we examine whether prediction errors differ across geographic groups, such as zip codes or spatial neighborhoods.\n",
    "\n",
    "If the model consistently:\n",
    "\n",
    "- Overestimates values in some areas\n",
    "- Underestimates values in others\n",
    "\n",
    "this may indicate unequal treatment depending on the location your house is in.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‹ Procedure\n",
    "\n",
    "1. Compute prediction errors for each house:\n",
    "   \n",
    "   Error = Actual Value âˆ’ Predicted Value  \n",
    "\n",
    "2. Group errors by geographic category (e.g., zip code or spatial cluster)\n",
    "\n",
    "3. Compare average error and RMSE across groups\n",
    "\n",
    "---\n",
    "\n",
    "### Question 7\n",
    "\n",
    "Analyze whether prediction errors differ systematically across locations.\n",
    "\n",
    "Answer the following:\n",
    "\n",
    "- Are some neighborhoods consistently overvalued or undervalued?\n",
    "- Which areas show the largest prediction errors?\n",
    "- What might explain these patterns?\n",
    "\n",
    "(any other observation you think is worth mentioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be handy to create a results DataFrame\n",
    "fairness_df = testing_data.copy()\n",
    "\n",
    "fairness_df[\"prediction\"] = y_pred_test\n",
    "fairness_df[\"error\"] = fairness_df[\"retailvalue\"] - fairness_df[\"prediction\"]\n",
    "fairness_df[\"abs_error\"] = np.abs(fairness_df[\"error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the error per-zipcode (hint: use groupby and agg?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot figure and show any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Analysis and answers to questions goes here**\n",
    "\n",
    "more text goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
